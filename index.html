<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .profile {
      border-radius: 50%;
    }

    .one {
      width: 160px;
      height: 160px;
      max-width: 100%;
      max-height: 100%;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <title> Nithin Rao</title>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114832734-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114832734-1');
</script>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name> Nithin Rao Koluguri</name>
              </p>
              <p> As a Senior Research Scientist &#64; <a href="https://developer.nvidia.com/conversational-ai">  NVIDIA Conversational AI,</a> I work on developing speaker recognition, verification and diarization systems. My research interests include speech signal processing, natural language processing and machine learning.</p> 
              <p>
                I received my masters degree from University of Southern California (USC) with a major in Electrical and Computer Engineering. During my masters I carried out research through <a href="https://sail.usc.edu/">Signal Analysis and Interpretation Laboratory (SAIL)</a> where I was advised by <a href="https://sail.usc.edu/people/shri.html">Prof. Shrikanth Narayanan</a>.
	      </p>
              <p align=center>
                <a href="mailto:nithinraok.koluguri@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://drive.google.com/open?id=1YKT0RKQfm1XQHRzGyf_YJ87odoa_eyGd">CV</a> &nbsp/&nbsp
                <a href="https://www.github.com/nithinraok">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/nithinraok/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://scholar.google.co.in/citations?user=YPtcUTUAAAAJ&hl=en"> Google Scholar  </a> &nbsp/&nbsp
                <a href="https://medium.com/@nithinraok_">Blog</a>
              </p>
            </td>
            <td width="33%">
              <img class="profile" src="images/nithin_new.png">
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
                <heading style="color:rgb(244, 189, 184);" >  Prior Work Experience </heading>
              <p>
                <papertitle> Applied Machine Learning Intern at <a href="https://www.bose.com/en_us/index.html" > Bose CE Applied Research Group</a> </papertitle>
                <!-- <br> -->
                <br>
                <ul>
                  <li>Developed and Deployed NLP & Computer Vision related ML system on Google pixel phone and Bose wearables</li>
                </ul>
                
              </p>
              
              <p>
                <papertitle> Research Assistant at <a href="https://spire.ee.iisc.ac.in/" > SPIRE LAB, IISc Bangalore </a> (Advised by: <a href="http://www.ee.iisc.ac.in/new/people/faculty/prasantg/">Prof. Prasanta Kumar Ghosh</a>) </papertitle>
                <!-- <br> -->
                <br>
                <ul>
                  <li>Built a speech classifier to detect Amyotrophic Lateral Sclerosis (ALS) and Parkinsons (PD) diseases based on voice as bio-marker</li>
                  <li>Developed an unsupervised system for robust bird sound detection using enhanced Multiple Window Savitzky-Golay (MWSG) spectrogram. </li>
                </ul>
              </p>
            
              <p>
                <papertitle> Software Developer at <a href="https://spire.ee.iisc.ac.in/" > Robert Bosch Bangalore </a> </papertitle>
                <!-- <br> -->
                <br>
                <ul>
                  <li>Customer and Production diagnosis in Telematics Projects, where designed new features for Daimler customer.</li>
                  <li>Text to speech (TTS) outputs for various car multimedia features like navigation, SMS readout and hands free control and tested the output using TTFIS tool</li>
                </ul>
              </p>

            </td>
          </tr>
        </table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading style="color:rgb(244, 189, 184);" >Research</heading>
              <p>
		I am interested in understanding signal level properties of audio,speech and Image. My research experiences thus far delve in natural language processing and applying machine learning algorithms on speech & image.
	      </p>
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          
          <tr>
            <!-- <td width="25%">
              <div class="one"><img src='images/speakernet.png'></div>
            </td> -->
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2203.15974">
                <papertitle>Multi-scale Speaker Diarization with Dynamic Scale Weighting</papertitle>
              </a>
              <br>
              Taejin Park, <strong> Nithin Rao Koluguri</strong>, Jagadeesh Balam, Boris Ginsburg
              <br>
              <br>
              <em>International Speech Communication Association (Interspeech), 2022 </em>
              <br>
              <a href="https://github.com/NVIDIA/NeMo">project page</a>
              <p></p>
              <p> Advanced multi-scale diarization system based on a multi-scale diarization decoder. </p>
            </td>
          </tr>

          <tr>
            <!-- <td width="25%">
              <div class="one"><img src='images/speakernet.png'></div>
            </td> -->
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2110.04410">
                <papertitle>TitaNet: Neural Model for speaker representation with 1D Depth-wise separable convolutions and global context</papertitle>
              </a>
              <br>
              <strong> Nithin Rao Koluguri</strong>,
              Taejin Park, Boris Ginsburg
              <br>
              <br>
              <em>International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022</em>
              <br>
              <a href="https://github.com/NVIDIA/NeMo">project page</a>
              <p></p>
              <p>A novel neural network architecture for extracting speaker representations. Employs 1D depth-wise separable convolutions with Squeeze-and-Excitation (SE) layers with global context followed by channel attention based statistics pooling layer to map variable-length utterances to a fixed-length embedding (t-vector). </p>
            </td>
          </tr>

          <tr>
            <!-- <td width="25%">
              <div class="one"><img src='images/speakernet.png'></div>
            </td> -->
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2010.12653">
                <papertitle>SpeakerNet: 1D Depth-wise Separable Convolutional Network for Text-Independent Speaker Recognition and Verification</papertitle>
              </a>
              <br>
              <strong> Nithin Rao Koluguri</strong>,
              Jason Li, Vitaly Lavrukhin, Boris Ginsburg
              <br>
              <br>
              <em>International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021</em>
              <br>
              <a href="https://github.com/NVIDIA/NeMo">project page</a>
              <p></p>
              <p>We propose SpeakerNet - a new neural architecture for speaker recognition and speaker verification tasks, this uses conv1D encoder and x-vector based statistics pooling decoder</p>
            </td>
          </tr>

          <tr>
            <!-- <td width="25%">
              <div class="one"><img src='images/proto_1.jpg'></div>
            </td>
             -->
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/1910.11400">
                <papertitle>Meta-learning for robust child-adult classification from speech</papertitle>
              </a>
              <br>
              <strong> Nithin Rao Koluguri</strong>,
              <a href="https://sail.usc.edu/~prabakar/">Manoj Kumar</a>,
              So Hyun Kim, Catherine Lord,
              <a href="https://sail.usc.edu/people/shri.php">Shrikanth Narayanan</a>
              <br>
              <br>
              <em>International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020</em>
              <br>
              <a href="https://github.com/usc-sail/care-proto-child-adult">project page</a>
              <p></p>
              <p>We demonstrate improvements over state-of-the-art speaker embeddings (x-vectors) for speaker classification using prototypical networks</p>
            </td>
          </tr>

          <tr>
            <!-- <td width="25%">
              <div class="one"><img src='images/ALS.png'></div>
            </td> -->
            <td valign="top" width="75%">
              <a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1285.pdf">
                <papertitle>Comparison Of Speech Tasks And Recording Devices For Voice Based Automatic Classification Of Healthy Subjects And Patients With Amyotrophic Lateral Sclerosis</papertitle>
              </a>
              <br>
              Suhas B.N,
              Deep Patel,
              <strong> Nithin Rao Koluguri</strong>,
              <a href="http://www.ee.iisc.ac.in/new/people/faculty/prasantg/">Prasanta Ghosh</a>*
              <br>
              <br>
              <em>International Speech Communication Association (Interspeech) </em>, 2019
              <br>
              <a href="http://spire.ee.iisc.ac.in/spire/allPublications.php">project page</a>
              <p></p>
              <p>We evaluated role of different speech tasks and recording devices in detecting ALS through speech</p>
            </td>
          </tr>

          <tr>
            <!-- <td width="25%">
              <div class="one"><img src='images/MWSG.png' width="200" height="120"></div>
            </td> -->
            <td valign="top" width="75%">
              <a href="https://ieeexplore.ieee.org/abstract/document/7933047">
                <papertitle>Spectrogram Enhancement Using Multiple Window Savitzky-Golay (MWSG) Filter for Robust Bird Sound Detection</papertitle>
              </a>
              <br>
              <strong>Nithin Rao Koluguri</strong>,
              <a href="http://www.ee.iisc.ac.in/new/people/students/phd/gnisha/index.html">Nisha G Meenakshi</a>*,
              <a href="http://www.ee.iisc.ac.in/new/people/faculty/prasantg/">Prasanta Ghosh</a>*
              <br>
              <br>
              <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 2017
              <br>
              <a href="https://github.com/nithinraok/MWSG_IEEE_Paper">project page</a>
              <p></p>
              <p>We propose a novel unsupervised method to denoise a spectrogram using Multiple Window Savitzky Golay algorithm, and use to enhance bird sound ques to recognize their sounds in noisy environments</p>
            </td>
          </tr>

        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading style="color:rgb(244, 189, 184);" > Projects</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">

          <tr>
            <!-- <td width="25%"><img src="images/sausage.jpg" width="200" height="120"></td> -->
            <td width="75%" valign="top">
              <p>
                <a href="">
                  <papertitle>Generating sausages from text using WFSTs without acoustic model (DR Project)</papertitle>
                </a>
    <br>
		<strong>Nithin Rao Koluguri</strong>, <a href="">Prashanth G</a>, <a href="https://viterbi.usc.edu/directory/faculty/Georgiou/Panayiotis">Prof. Panayiotis Georgiou,</a>  2019 
		<br>
		<br> Developed a method to mimic an ASR for a given Noise type at certain db level to generate nbest paths from text alone using sausages and confusion matrix. Generated text can be used swiftly to improve an ASR correction model.<br>
              </p>
            </td>
          </tr>
          <tr>
            <!-- <td width="25%"><img src="images/VQA.png" width="200" height="160"></td> -->
            <td width="75%" valign="top">
              <p>
                <a href="https://medium.com/@nithinraok_/visual-question-answering-attention-and-fusion-based-approaches-ebef62fa55aa">
                  <papertitle>Visual Question Answering &#8208 Attention and Fusion based approaches</papertitle>
                </a>
                <br>
		<strong>Nithin Rao Koluguri</strong>, <a href="https://github.com/digbose92">Digbalay Bose</a>,<a href=""> Namrata Tam</a>,  Aditya Mate 2019 
                <br>
                <br> Explored Visual Question Answering methods and looked at applying attention and fusion based methods specifically bottom-up and top-down. Explored BERT Embeddings and different representations for decent VQA system.
                
              </p>
            </td>
          </tr>

	  <tr>
            <!-- <td width="25%"><img src="images/kaldi.png" width="200" height="160"></td> -->
            <td width="75%" valign="top">
              <p>
                <a href="https://github.com/nithinraok/Decision-level-data-fusion-of-Image-and-Speech-recognition-system">
                  <papertitle>Image recognition system based on speech command</papertitle>
                </a>
                <br>
		<strong>Nithin Rao Koluguri</strong>, Nikhil, Gaurav Newalkar, 2016 
                <br>
                  <br> Designed an image recognition system based on the input given through speech. The goal of the project is to assist visual-impaired persons to know the coordinates of the object they are looking for just by their speech. The system on overall achieved an accuracy of 93.75% on speech digits
              </p>
            </td>
	  </tr> 
        </table>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading style="color:rgb(244, 189, 184);" >Blogs</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <!-- <td width="25%"><img src="images/Blog.png" width="200" height="160"></td> -->
            <td width="75%" valign="top">
              <p>
                <a href="https://medium.com/@nithinraok_/decoding-an-audio-file-using-a-pre-trained-model-with-kaldi-c1d7d2fe3dc5">
                  <papertitle>Decoding an audio file using a pre-trained model with Kaldi</papertitle>
                </a>
		</p>

		<p>
                <a href="https://medium.com/@nithinraok_/how-to-get-timestamps-of-an-audio-file-using-pre-trained-model-with-kaldi-7b279f59fcde">
                  <papertitle>How to get timestamps of an audio file using pre-trained model with Kaldi</papertitle>
                </a>
              </p>

		<p>
                <a href="https://medium.com/@nithinraok_/visual-question-answering-attention-and-fusion-based-approaches-ebef62fa55aa">
                  <papertitle>Visual Question Answering &#8208 Attention and Fusion based approaches</papertitle>
                </a>
              </p>

            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr><td>
          <br>
            <p align="right"><font size="2">
            <a href="http://www.cs.berkeley.edu/~barron/">inspired from this website</a>
            </font></p>
          </td></tr></tbody>
        </table>
        </td>
    </tr>
  </table>
</body>

</html>
